{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find Spark installation\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add spark-csv package and jdbc driver\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.1.0 pyspark-shell'\n",
    "os.environ['SPARK_CLASSPATH'] = '/home/h_tariq/email_pressure/lib/sqljdbc4.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import pymssql\n",
    "import itertools as IT\n",
    "from datetime import datetime\n",
    "from json2html import json2html\n",
    "from IPython.core.display import HTML, display\n",
    "from numpy import array\n",
    "from pandas import Series\n",
    "import xgboost as xgb\n",
    "import numpy\n",
    "from collections import Counter, OrderedDict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PySpark imports\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PySpark initialization\n",
    "sc = SparkContext(appName='GenderPrediction')\n",
    "\n",
    "# SQLContext initializatino\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sql.read.format('com.databricks.spark.csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferschema', 'true') \\\n",
    "    .load('export_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = df.filter(df.GENDER.isin(['0', '1']))\n",
    "test = df.subtract(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = train.cache()\n",
    "_ = test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134257\n",
      "3160042\n"
     ]
    }
   ],
   "source": [
    "print train.count()\n",
    "print test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47187\n"
     ]
    }
   ],
   "source": [
    "top_n = 1000\n",
    "categorical_variables = [\"trafficSource_source\", \"device_operatingSystem\", \"device_browser\", \"geoNetwork_country\",\n",
    "                         \"pagetype\", \"webshop\", \"device_deviceCategory\", \"trafficSource_medium\", 'productid', \n",
    "                         \"PRODUCTTYPEID\", \"BRANDID\"]\n",
    "categorical_dict = {}\n",
    "other_product_var = {}\n",
    "\n",
    "for var in categorical_variables:\n",
    "    if var == 'productid':\n",
    "        all_train = sorted([(x[1], x[0].lower().strip()) for x in train.groupBy(var).count().collect()], reverse=True)\n",
    "        all_test = sorted([(x[1], x[0].lower().strip()) for x in test.groupBy(var).count().collect()], reverse=True)\n",
    "        common = set([x[1] for x in all_train]).intersection(set([x[1] for x in all_test]))\n",
    "        series = Series(list(common))\n",
    "        other_product_var = {v: k for k, v in series.to_dict().items()}\n",
    "    all_train = sorted([(x[1], x[0].lower().strip()) for x in train.groupBy(var).count().collect()], reverse=True)[:top_n]\n",
    "    all_test = sorted([(x[1], x[0].lower().strip()) for x in test.groupBy(var).count().collect()], reverse=True)[:top_n]\n",
    "    common = set([x[1] for x in all_train]).intersection(set([x[1] for x in all_test]))\n",
    "    series = Series(list(common))\n",
    "    categorical_dict[var] = {v: k for k, v in enumerate(common)}\n",
    "\n",
    "print len(other_product_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webshop: 331\n",
      "trafficSource_medium: 56\n",
      "geoNetwork_country: 114\n",
      "BRANDID: 938\n",
      "trafficSource_source: 670\n",
      "device_operatingSystem: 11\n",
      "pagetype: 20\n",
      "device_browser: 22\n",
      "PRODUCTTYPEID: 910\n",
      "device_deviceCategory: 3\n",
      "productid: 695\n"
     ]
    }
   ],
   "source": [
    "for k, v in categorical_dict.items():\n",
    "    print '%s: %s' %(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'mobile': 0, u'tablet': 1, u'desktop': 2}\n"
     ]
    }
   ],
   "source": [
    "print categorical_dict[\"device_deviceCategory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print categorical_dict[\"geoNetwork_country\"][\"netherlands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = test.rdd + train.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def type_casting(x):\n",
    "    inner = ()\n",
    "    \n",
    "    gender = x.GENDER\n",
    "    timestamp = datetime.strptime('%s %s:%s:00.0' %(x.date, x.hour, x.minute) , '%Y%m%d %H:%M:00.0')\n",
    "    inner += (timestamp,)\n",
    "    inner += (timestamp.hour, timestamp.minute, timestamp.day, timestamp.weekday(), timestamp.isocalendar()[1],)\n",
    "    \n",
    "    inner += (x.totals_pageviews,)\n",
    "    inner += (x.totals_timeOnSite,)\n",
    "\n",
    "    inner += (x.trafficSource_source.lower().strip(),)\n",
    "    inner += (x.device_operatingSystem.lower().strip(),)\n",
    "    inner += (x.device_browser.lower().strip(),)\n",
    "    inner += (x.geoNetwork_country.lower().strip(),)\n",
    "    inner += (x.pagetype.lower().strip(),)\n",
    "    inner += (x.webshop.lower().strip(),)\n",
    "    inner += (x.device_deviceCategory.lower().strip(),)\n",
    "    inner += (x.trafficSource_medium.lower().strip(),)\n",
    "    \n",
    "    inner += (x.productid,)\n",
    "    inner += (x.PRODUCTTYPEID,)\n",
    "    inner += (x.BRANDID,)\n",
    "    \n",
    "    inner += (gender,)\n",
    "\n",
    "    return ('%s-%s ' %(x.FVID, x.VID), inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MapReduce Job 1 - Sample Output:\n",
      "\n",
      "[(u'65514942951814451-1447235808 ', (datetime.datetime(2015, 11, 11, 11, 23), 11, 23, 11, 2, 46, u'25', u'1807', u'google', u'macintosh', u'safari', u'netherlands', u'product', u'www.domoticaexpert.nl', u'desktop', u'organic', u'644074', u'4796', u'2287', u'7853520'))]\n"
     ]
    }
   ],
   "source": [
    "# Map again by grouping by key email\n",
    "data = data.map(type_casting)\n",
    "print '\\nMapReduce Job 1 - Sample Output:\\n'\n",
    "print data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce by adding all the lists for each session together\n",
    "data = data.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapper_timestamp_sort(x):\n",
    "    \"\"\"\n",
    "    Map the resulting data by session again and sort the records by timestamp\n",
    "    \"\"\"\n",
    "    y = x[1]\n",
    "    inner = []\n",
    "    for indx in xrange(0, len(y), 20):\n",
    "        tmp = [item for sublist in [[y[indx]], y[indx+1:indx+20]] for item in sublist]\n",
    "        inner.append(tuple(tmp))\n",
    "    inner = sorted(inner, key=lambda x: x[0])\n",
    "    return (x[0], inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.map(mapper_timestamp_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median(lst):\n",
    "    return numpy.median(numpy.array(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = OrderedDict()\n",
    "for x in categorical_variables:\n",
    "    matrix[x] = [0] * (len(categorical_dict[x]) + 1)\n",
    "\n",
    "def mapper_add_cumulative_features(x):\n",
    "    \"\"\"\n",
    "    Transform, calculate, and add new features:\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    def get_index(key, val):\n",
    "        try:\n",
    "            return categorical_dict[key][val]\n",
    "        except KeyError:\n",
    "            return -1\n",
    "    \n",
    "    inner_matrix = OrderedDict(deepcopy(matrix))\n",
    "    \n",
    "    y = x[1]\n",
    "    timestamps = []\n",
    "    hours, weekdays, woys, sources, os_s, browsers, shops, devices, mediums = [], [], [], [], [], [], [], [], []\n",
    "    page_types, products, producttypes, brands = [], [], [], []\n",
    "    for timestamp, hour, minute, day, weekday, woy, page_views, time_on_site,\\\n",
    "        source, os, browser, country, page_type, shop, device, medium, prod_id, prodtype_id, brand, gender in y:\n",
    "        \n",
    "        timestamps.append(timestamp)\n",
    "        hours.append(hour + (minute/60.0))\n",
    "        weekdays.append(weekday)\n",
    "        woys.append(woy)\n",
    "        \n",
    "        try:\n",
    "            productid_all = other_product_var[prod_id]\n",
    "        except KeyError:\n",
    "            productid_all = -1\n",
    "        products.append(productid_all)\n",
    "        \n",
    "        inner_matrix[\"trafficSource_source\"][get_index(\"trafficSource_source\", source)] += 1\n",
    "        inner_matrix[\"device_operatingSystem\"][get_index(\"device_operatingSystem\", os)] += 1\n",
    "        inner_matrix[\"device_browser\"][get_index(\"device_browser\", browser)] += 1\n",
    "        inner_matrix[\"geoNetwork_country\"][get_index(\"geoNetwork_country\", country)] += 1\n",
    "        inner_matrix[\"pagetype\"][get_index(\"pagetype\", page_type)] += 1\n",
    "        inner_matrix[\"webshop\"][get_index(\"webshop\", shop)] += 1\n",
    "        inner_matrix[\"device_deviceCategory\"][get_index(\"device_deviceCategory\", device)] += 1\n",
    "        inner_matrix[\"trafficSource_medium\"][get_index(\"trafficSource_medium\", medium)] += 1\n",
    "        inner_matrix[\"productid\"][get_index(\"productid\", prod_id)] += 1\n",
    "        inner_matrix[\"PRODUCTTYPEID\"][get_index(\"PRODUCTTYPEID\", prodtype_id)] += 1\n",
    "        inner_matrix[\"BRANDID\"][get_index(\"BRANDID\", brand)] += 1\n",
    "    \n",
    "    hour = median(hours)\n",
    "    weekday = Counter(weekdays).most_common(1)[0][0]\n",
    "    woy = Counter(woys).most_common(1)[0][0]\n",
    "    # Exclude week of the year for now\n",
    "    woy = 0\n",
    "    product = Counter(products).most_common(1)[0][0]\n",
    "    \n",
    "    unique_products = len(set(products))\n",
    "    unique_product_types = len(set(producttypes))\n",
    "    unique_shops = len(set(shops))\n",
    "    \n",
    "    total_pages = len(hours)\n",
    "    time_on_site = (timestamps[-1]-timestamps[0]).total_seconds()\n",
    "    time_per_page = time_on_site / float(total_pages)\n",
    "    \n",
    "    data = [hour, weekday, woy, product, unique_products, unique_product_types, unique_shops, total_pages, time_on_site, \\\n",
    "            time_per_page]\n",
    "    \n",
    "    data += [item for sublist in inner_matrix.values() for item in sublist]\n",
    "       \n",
    "    return LabeledPoint(gender, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.map(mapper_add_cumulative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_data = data.filter(lambda x: x.label < 2.0)\n",
    "test_data = data.filter(lambda x: x.label > 2.0)\n",
    "\n",
    "all_1s = train_test_data.filter(lambda x: x.label==1.0)\n",
    "all_0s = train_test_data.filter(lambda x: x.label==0.0)\n",
    "\n",
    "# NOT using test_eval_data for now\n",
    "# (training_data_1, test_eval_data_1) = all_1s.randomSplit([0.7, 0.3])\n",
    "# (training_data_0, test_eval_data_0) = all_0s.randomSplit([0.7, 0.3])\n",
    "\n",
    "# training_data = training_data_1 + training_data_0\n",
    "training_data = all_1s + all_0s\n",
    "# test_eval_data = test_eval_data_1 + test_eval_data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_location = 'gender_train'\n",
    "test_location = 'gender_test'\n",
    "eval_location = 'gender_test_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(train_location)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(test_location)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(eval_location)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data transformed in: 2091.66101503\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "MLUtils.saveAsLibSVMFile(training_data, train_location)\n",
    "# MLUtils.saveAsLibSVMFile(test_eval_data, eval_location)\n",
    "MLUtils.saveAsLibSVMFile(test_data, test_location)\n",
    "print '\\nData transformed in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[225] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_1s.unpersist()\n",
    "all_0s.unpersist()\n",
    "\n",
    "training_data.unpersist()\n",
    "# test_eval_data.unpersist()\n",
    "train_test_data.unpersist()\n",
    "test_data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved in: 1184.66550899\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "_ = os.system('cat %s/part-00* > %s.txt' %(train_location, train_location))\n",
    "_ = os.system('cat %s/part-00* > %s.txt' %(test_location, test_location))\n",
    "# _ = os.system('cat %s/part-00* > %s.txt' %(eval_location, eval_location))\n",
    "print '\\nData saved in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data re-loaded in: 296.883789062\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "pre = ''\n",
    "tr_xgb = xgb.DMatrix('%s%s.txt' %(pre, train_location))\n",
    "# ts_eval_xgb = xgb.DMatrix('%s%s.txt' %(pre, eval_location))\n",
    "print '\\nData re-loaded in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_loc = 'model/gender_4.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "st = time.time()\n",
    "\n",
    "param = {\n",
    "        \"silent\": 1,\n",
    "        \"objective\": \"binary:logistic\",   \n",
    "        \"eval_metric\": \"auc\",           # evaluation metric \n",
    "        \"nthread\": 40,                  # number of threads to be used \n",
    "        \"max_depth\": 4,                 # maximum depth of tree \n",
    "        # \"eta\": 0.10,                    # step size shrinkage \n",
    "        \"eta\": 0.04,                    # step size shrinkage \n",
    "        # \"subsample\": 0.6,               # part of data instances to grow tree \n",
    "        \"subsample\": 0.4,               # part of data instances to grow tree \n",
    "        # \"colsample_bytree\": 0.8,        # subsample ratio of columns when constructing each tree \n",
    "        \"colsample_bytree\": 0.4,        # subsample ratio of columns when constructing each tree \n",
    "        # \"min_child_weight\": 3,          # minimum sum of instance weight needed in a child \n",
    "        \"min_child_weight\": 1,          # minimum sum of instance weight needed in a child\n",
    "}\n",
    "plst = param.items()\n",
    "\n",
    "num_round = 4000\n",
    "try:\n",
    "    bst = xgb.train(plst, tr_xgb, num_round, evals=((tr_xgb, 'eval'),), early_stopping_rounds=200, xgb_model=model_loc)\n",
    "except:\n",
    "    bst = xgb.train(plst, tr_xgb, num_round, evals=((tr_xgb, 'eval'),), early_stopping_rounds=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 13583.680423\n"
     ]
    }
   ],
   "source": [
    "print '\\nTraining completed in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model(model_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999\n",
      "0.749864\n"
     ]
    }
   ],
   "source": [
    "print bst.best_iteration\n",
    "print bst.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# _ = xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del tr_xgb\n",
    "# del ts_eval_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('sudo su -c \"echo 1 > /proc/sys/vm/drop_caches\"')\n",
    "os.system('sudo su -c \"echo 2 > /proc/sys/vm/drop_caches\"')\n",
    "os.system('sudo su -c \"echo 3 > /proc/sys/vm/drop_caches\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data re-loaded in: 291.265121222\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "ts_xgb = xgb.DMatrix('%s%s.txt' %(pre, test_location))\n",
    "print '\\nData re-loaded in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions made in: 22.0992760658\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "predicted_values = bst.predict(ts_xgb, ntree_limit=bst.best_ntree_limit)\n",
    "print '\\nPredictions made in: %s' %(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ts_xgb.get_label()\n",
    "del ts_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('sudo su -c \"echo 1 > /proc/sys/vm/drop_caches\"')\n",
    "os.system('sudo su -c \"echo 2 > /proc/sys/vm/drop_caches\"')\n",
    "os.system('sudo su -c \"echo 3 > /proc/sys/vm/drop_caches\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5706\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "mapping = {}\n",
    "mdf = sql.read.format('com.databricks.spark.csv') \\\n",
    "     .option('header', 'true') \\\n",
    "     .option('inferschema', 'true') \\\n",
    "     .load('export_gender_mapping')\n",
    "\n",
    "for x in mdf.collect():\n",
    "    (fullVisitorId, visitId, ID) = x.fullVisitorId, x.visitId, x.ID\n",
    "    mapping[int(ID)] = (fullVisitorId, visitId)\n",
    "\n",
    "cnt = 0\n",
    "for indx, x in enumerate(predicted_values):\n",
    "    key = int(labels[indx]/10)\n",
    "    (fullVisitorId, visitId) = mapping[key]\n",
    "    prediction = 1 if x > 0.49 else 0\n",
    "    if prediction:\n",
    "        cnt+=1\n",
    "    # predictions[(fullVisitorId, visitId)] = prediction\n",
    "    predictions[(fullVisitorId, visitId)] = x\n",
    "\n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fl = open('gender_predictions.csv', 'w')\n",
    "\n",
    "for k, v in predictions.items():\n",
    "    prediction = v\n",
    "    (fullVisitorId, visitId) = k[0], k[1]\n",
    "    fl.write('%s,%s,%s\\n' %(fullVisitorId, visitId, prediction))\n",
    "\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
